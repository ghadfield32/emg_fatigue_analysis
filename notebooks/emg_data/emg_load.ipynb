{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] Found 4 CSV files in '../../data/raw/emg_data/'.\n",
      "\n",
      "[process_file] Processing file: ../../data/raw/emg_data\\2-14-25_bullpen_1.csv\n",
      "[read_sensor_data_with_metadata] Format detected: FULL_FORMAT\n",
      "[read_sensor_data_with_metadata] SensorGroups: ['FDS (81770)', 'FDS (81770)', 'FDS (81770)', 'FDS (81770)', 'FDS (81770)', 'FDS (81770)', 'FDS (81770)', 'FCU (81728)', 'FCU (81728)', 'FCU (81728)', 'FCU (81728)', 'FCU (81728)', 'FCU (81728)', 'FCU (81728)', 'FCR (81745)']\n",
      "[read_sensor_data_with_metadata] SensorModes: ['sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 40']\n",
      "[read_sensor_data_with_metadata] New column names set with sensor names.\n",
      "[read_sensor_data_with_metadata] Using column names: ['EMG 1 (mV) - FDS', 'ACC X (G) - FDS', 'ACC Y (G) - FDS', 'ACC Z (G) - FDS', 'GYRO X (deg/s) - FDS', 'GYRO Y (deg/s) - FDS', 'GYRO Z (deg/s) - FDS', 'EMG 1 (mV) - FCU', 'ACC X (G) - FCU', 'ACC Y (G) - FCU', 'ACC Z (G) - FCU', 'GYRO X (deg/s) - FCU', 'GYRO Y (deg/s) - FCU', 'GYRO Z (deg/s) - FCU', 'EMG 1 (mV) - FCR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GeoffreyHadfield\\AppData\\Local\\Temp\\ipykernel_20668\\1057916375.py:226: DtypeWarning: Columns (1,2,3,4,5,6,8,9,10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(StringIO(data_str), header=None, names=new_col_names)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[read_sensor_data_with_metadata] Missing ACC columns for FCR\n",
      "[read_sensor_data_with_metadata] Missing GYRO columns for FCR\n",
      "[read_sensor_data_with_metadata] Final DataFrame shape: (182675, 27)\n",
      "[read_sensor_data_with_metadata] Final column names: ['EMG 1 (mV) - FDS', 'ACC X (G) - FDS', 'ACC Y (G) - FDS', 'ACC Z (G) - FDS', 'GYRO X (deg/s) - FDS', 'GYRO Y (deg/s) - FDS', 'GYRO Z (deg/s) - FDS', 'EMG 1 (mV) - FCU', 'ACC X (G) - FCU', 'ACC Y (G) - FCU', 'ACC Z (G) - FCU', 'GYRO X (deg/s) - FCU', 'GYRO Y (deg/s) - FCU', 'GYRO Z (deg/s) - FCU', 'EMG 1 (mV) - FCR', 'Timestamp', 'Application', 'Date/Time', 'Collection Length (seconds)', 'HasTimeSeries', 'FileFormat', 'ACC X (G) - FCR', 'ACC Y (G) - FCR', 'ACC Z (G) - FCR', 'GYRO X (deg/s) - FCR', 'GYRO Y (deg/s) - FCR', 'GYRO Z (deg/s) - FCR']\n",
      "[process_file] Format: FULL_FORMAT\n",
      "[process_file] DataFrame shape after reading: (182675, 27)\n",
      "[process_file] Descriptive Statistics:\n",
      "       EMG 1 (mV) - FDS  EMG 1 (mV) - FCU  EMG 1 (mV) - FCR  \\\n",
      "count     182675.000000     182675.000000     182675.000000   \n",
      "mean          -0.004528         -0.009749          0.011987   \n",
      "min           -3.431678         -1.700481         -4.816098   \n",
      "25%           -0.018296         -0.016449          0.001175   \n",
      "50%           -0.005203         -0.009567          0.011582   \n",
      "75%            0.007217         -0.002182          0.021653   \n",
      "max            1.849531          1.302007          4.703304   \n",
      "std            0.102074          0.065169          0.068522   \n",
      "\n",
      "                           Timestamp  ACC X (G) - FCR  ACC Y (G) - FCR  \\\n",
      "count                         182675              0.0              0.0   \n",
      "mean   2025-02-14 11:49:56.680000256              NaN              NaN   \n",
      "min              2025-02-14 11:42:22              NaN              NaN   \n",
      "25%       2025-02-14 11:46:09.340000              NaN              NaN   \n",
      "50%       2025-02-14 11:49:56.680000              NaN              NaN   \n",
      "75%       2025-02-14 11:53:44.020000              NaN              NaN   \n",
      "max       2025-02-14 11:57:31.360000              NaN              NaN   \n",
      "std                              NaN              NaN              NaN   \n",
      "\n",
      "       ACC Z (G) - FCR  GYRO X (deg/s) - FCR  GYRO Y (deg/s) - FCR  \\\n",
      "count              0.0                   0.0                   0.0   \n",
      "mean               NaN                   NaN                   NaN   \n",
      "min                NaN                   NaN                   NaN   \n",
      "25%                NaN                   NaN                   NaN   \n",
      "50%                NaN                   NaN                   NaN   \n",
      "75%                NaN                   NaN                   NaN   \n",
      "max                NaN                   NaN                   NaN   \n",
      "std                NaN                   NaN                   NaN   \n",
      "\n",
      "       GYRO Z (deg/s) - FCR  \n",
      "count                   0.0  \n",
      "mean                    NaN  \n",
      "min                     NaN  \n",
      "25%                     NaN  \n",
      "50%                     NaN  \n",
      "75%                     NaN  \n",
      "max                     NaN  \n",
      "std                     NaN  \n",
      "[process_file] Data types:\n",
      "EMG 1 (mV) - FDS                      float64\n",
      "ACC X (G) - FDS                        object\n",
      "ACC Y (G) - FDS                        object\n",
      "ACC Z (G) - FDS                        object\n",
      "GYRO X (deg/s) - FDS                   object\n",
      "GYRO Y (deg/s) - FDS                   object\n",
      "GYRO Z (deg/s) - FDS                   object\n",
      "EMG 1 (mV) - FCU                      float64\n",
      "ACC X (G) - FCU                        object\n",
      "ACC Y (G) - FCU                        object\n",
      "ACC Z (G) - FCU                        object\n",
      "GYRO X (deg/s) - FCU                   object\n",
      "GYRO Y (deg/s) - FCU                   object\n",
      "GYRO Z (deg/s) - FCU                   object\n",
      "EMG 1 (mV) - FCR                      float64\n",
      "Timestamp                      datetime64[ns]\n",
      "Application                            object\n",
      "Date/Time                              object\n",
      "Collection Length (seconds)            object\n",
      "HasTimeSeries                            bool\n",
      "FileFormat                             object\n",
      "ACC X (G) - FCR                       float64\n",
      "ACC Y (G) - FCR                       float64\n",
      "ACC Z (G) - FCR                       float64\n",
      "GYRO X (deg/s) - FCR                  float64\n",
      "GYRO Y (deg/s) - FCR                  float64\n",
      "GYRO Z (deg/s) - FCR                  float64\n",
      "dtype: object\n",
      "[process_file] Identified numeric sensor columns: ['ACC X (G) - FDS', 'ACC X (G) - FCU', 'ACC X (G) - FCR', 'ACC Y (G) - FDS', 'ACC Y (G) - FCU', 'ACC Y (G) - FCR', 'ACC Z (G) - FDS', 'ACC Z (G) - FCU', 'ACC Z (G) - FCR', 'GYRO X (deg/s) - FDS', 'GYRO X (deg/s) - FCU', 'GYRO X (deg/s) - FCR', 'GYRO Y (deg/s) - FDS', 'GYRO Y (deg/s) - FCU', 'GYRO Y (deg/s) - FCR', 'GYRO Z (deg/s) - FDS', 'GYRO Z (deg/s) - FCU', 'GYRO Z (deg/s) - FCR', 'EMG 1 (mV) - FDS', 'EMG 1 (mV) - FCU', 'EMG 1 (mV) - FCR']\n",
      "[process_file] Rows with blank numeric values: 47955\n",
      "[process_file] Data shape after cleaning: (134720, 27)\n",
      "File processing completed.\n",
      "\n",
      "\n",
      "[process_file] Processing file: ../../data/raw/emg_data\\2-19-25_throws_1.csv\n",
      "[read_sensor_data_with_metadata] Format detected: FULL_FORMAT\n",
      "[read_sensor_data_with_metadata] SensorGroups: ['FDS (81770)', 'FDS (81770)', 'FDS (81770)', 'FDS (81770)', 'FDS (81770)', 'FDS (81770)', 'FDS (81770)', 'FCU (81728)', 'FCU (81728)', 'FCU (81728)', 'FCU (81728)', 'FCU (81728)', 'FCU (81728)', 'FCU (81728)', 'FCR (81745)']\n",
      "[read_sensor_data_with_metadata] SensorModes: ['sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 50', 'sensor mode: 40']\n",
      "[read_sensor_data_with_metadata] New column names set with sensor names.\n",
      "[read_sensor_data_with_metadata] Using column names: ['EMG 1 (mV) - FDS', 'ACC X (G) - FDS', 'ACC Y (G) - FDS', 'ACC Z (G) - FDS', 'GYRO X (deg/s) - FDS', 'GYRO Y (deg/s) - FDS', 'GYRO Z (deg/s) - FDS', 'EMG 1 (mV) - FCU', 'ACC X (G) - FCU', 'ACC Y (G) - FCU', 'ACC Z (G) - FCU', 'GYRO X (deg/s) - FCU', 'GYRO Y (deg/s) - FCU', 'GYRO Z (deg/s) - FCU', 'EMG 1 (mV) - FCR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GeoffreyHadfield\\AppData\\Local\\Temp\\ipykernel_20668\\1057916375.py:226: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(StringIO(data_str), header=None, names=new_col_names)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[read_sensor_data_with_metadata] Missing ACC columns for FCR\n",
      "[read_sensor_data_with_metadata] Missing GYRO columns for FCR\n",
      "[read_sensor_data_with_metadata] Final DataFrame shape: (2535557, 27)\n",
      "[read_sensor_data_with_metadata] Final column names: ['EMG 1 (mV) - FDS', 'ACC X (G) - FDS', 'ACC Y (G) - FDS', 'ACC Z (G) - FDS', 'GYRO X (deg/s) - FDS', 'GYRO Y (deg/s) - FDS', 'GYRO Z (deg/s) - FDS', 'EMG 1 (mV) - FCU', 'ACC X (G) - FCU', 'ACC Y (G) - FCU', 'ACC Z (G) - FCU', 'GYRO X (deg/s) - FCU', 'GYRO Y (deg/s) - FCU', 'GYRO Z (deg/s) - FCU', 'EMG 1 (mV) - FCR', 'Timestamp', 'Application', 'Date/Time', 'Collection Length (seconds)', 'HasTimeSeries', 'FileFormat', 'ACC X (G) - FCR', 'ACC Y (G) - FCR', 'ACC Z (G) - FCR', 'GYRO X (deg/s) - FCR', 'GYRO Y (deg/s) - FCR', 'GYRO Z (deg/s) - FCR']\n",
      "[process_file] Format: FULL_FORMAT\n",
      "[process_file] DataFrame shape after reading: (2535557, 27)\n",
      "[process_file] Descriptive Statistics:\n",
      "       EMG 1 (mV) - FDS  EMG 1 (mV) - FCR                      Timestamp  \\\n",
      "count      1.486361e+06      2.535557e+06                        2535557   \n",
      "mean      -2.623509e-03      1.236201e-02  2025-02-19 13:06:34.172750336   \n",
      "min       -5.496391e+00     -5.491188e+00            2025-02-19 12:56:44   \n",
      "25%       -1.091020e-02      4.867600e-03  2025-02-19 13:01:39.086374912   \n",
      "50%       -8.392000e-04      1.225300e-02  2025-02-19 13:06:34.172750080   \n",
      "75%        2.517700e-03      1.963840e-02  2025-02-19 13:11:29.259124992   \n",
      "max        5.495888e+00      3.180911e+00     2025-02-19 13:16:24.345500   \n",
      "std        2.669300e-01      4.274142e-02                            NaN   \n",
      "\n",
      "       ACC X (G) - FCR  ACC Y (G) - FCR  ACC Z (G) - FCR  \\\n",
      "count              0.0              0.0              0.0   \n",
      "mean               NaN              NaN              NaN   \n",
      "min                NaN              NaN              NaN   \n",
      "25%                NaN              NaN              NaN   \n",
      "50%                NaN              NaN              NaN   \n",
      "75%                NaN              NaN              NaN   \n",
      "max                NaN              NaN              NaN   \n",
      "std                NaN              NaN              NaN   \n",
      "\n",
      "       GYRO X (deg/s) - FCR  GYRO Y (deg/s) - FCR  GYRO Z (deg/s) - FCR  \n",
      "count                   0.0                   0.0                   0.0  \n",
      "mean                    NaN                   NaN                   NaN  \n",
      "min                     NaN                   NaN                   NaN  \n",
      "25%                     NaN                   NaN                   NaN  \n",
      "50%                     NaN                   NaN                   NaN  \n",
      "75%                     NaN                   NaN                   NaN  \n",
      "max                     NaN                   NaN                   NaN  \n",
      "std                     NaN                   NaN                   NaN  \n",
      "[process_file] Data types:\n",
      "EMG 1 (mV) - FDS                      float64\n",
      "ACC X (G) - FDS                        object\n",
      "ACC Y (G) - FDS                        object\n",
      "ACC Z (G) - FDS                        object\n",
      "GYRO X (deg/s) - FDS                   object\n",
      "GYRO Y (deg/s) - FDS                   object\n",
      "GYRO Z (deg/s) - FDS                   object\n",
      "EMG 1 (mV) - FCU                       object\n",
      "ACC X (G) - FCU                        object\n",
      "ACC Y (G) - FCU                        object\n",
      "ACC Z (G) - FCU                        object\n",
      "GYRO X (deg/s) - FCU                   object\n",
      "GYRO Y (deg/s) - FCU                   object\n",
      "GYRO Z (deg/s) - FCU                   object\n",
      "EMG 1 (mV) - FCR                      float64\n",
      "Timestamp                      datetime64[ns]\n",
      "Application                            object\n",
      "Date/Time                              object\n",
      "Collection Length (seconds)            object\n",
      "HasTimeSeries                            bool\n",
      "FileFormat                             object\n",
      "ACC X (G) - FCR                       float64\n",
      "ACC Y (G) - FCR                       float64\n",
      "ACC Z (G) - FCR                       float64\n",
      "GYRO X (deg/s) - FCR                  float64\n",
      "GYRO Y (deg/s) - FCR                  float64\n",
      "GYRO Z (deg/s) - FCR                  float64\n",
      "dtype: object\n",
      "[process_file] Identified numeric sensor columns: ['ACC X (G) - FDS', 'ACC X (G) - FCU', 'ACC X (G) - FCR', 'ACC Y (G) - FDS', 'ACC Y (G) - FCU', 'ACC Y (G) - FCR', 'ACC Z (G) - FDS', 'ACC Z (G) - FCU', 'ACC Z (G) - FCR', 'GYRO X (deg/s) - FDS', 'GYRO X (deg/s) - FCU', 'GYRO X (deg/s) - FCR', 'GYRO Y (deg/s) - FDS', 'GYRO Y (deg/s) - FCU', 'GYRO Y (deg/s) - FCR', 'GYRO Z (deg/s) - FDS', 'GYRO Z (deg/s) - FCU', 'GYRO Z (deg/s) - FCR', 'EMG 1 (mV) - FDS', 'EMG 1 (mV) - FCU', 'EMG 1 (mV) - FCR']\n",
      "[process_file] Rows with blank numeric values: 2360691\n",
      "[process_file] Data shape after cleaning: (174866, 27)\n",
      "File processing completed.\n",
      "\n",
      "\n",
      "[process_file] Processing file: ../../data/raw/emg_data\\2-27-25_mocap_1 copy.csv\n",
      "[read_sensor_data_with_metadata] Format detected: COMPACT_FORMAT\n",
      "[read_sensor_data_with_metadata] SensorGroups: ['FCU (81770)', 'FCR (81745)']\n",
      "[read_sensor_data_with_metadata] SensorModes: ['sensor mode: 40', 'sensor mode: 40']\n",
      "[read_sensor_data_with_metadata] New column names set with sensor names.\n",
      "[read_sensor_data_with_metadata] Using column names: ['EMG 1 (mV) - FCU', 'EMG 1 (mV) - FCR']\n",
      "[read_sensor_data_with_metadata] Missing sensors: ['FDS']\n",
      "[read_sensor_data_with_metadata] Missing ACC columns for FCU\n",
      "[read_sensor_data_with_metadata] Missing GYRO columns for FCU\n",
      "[read_sensor_data_with_metadata] Missing ACC columns for FCR\n",
      "[read_sensor_data_with_metadata] Missing GYRO columns for FCR\n",
      "[read_sensor_data_with_metadata] Final DataFrame shape: (662099, 27)\n",
      "[read_sensor_data_with_metadata] Final column names: ['EMG 1 (mV) - FCU', 'EMG 1 (mV) - FCR', 'Timestamp', 'Application', 'Date/Time', 'Collection Length (seconds)', 'HasTimeSeries', 'FileFormat', 'EMG 1 (mV) - FDS', 'ACC X (G) - FDS', 'ACC Y (G) - FDS', 'ACC Z (G) - FDS', 'GYRO X (deg/s) - FDS', 'GYRO Y (deg/s) - FDS', 'GYRO Z (deg/s) - FDS', 'ACC X (G) - FCU', 'ACC Y (G) - FCU', 'ACC Z (G) - FCU', 'GYRO X (deg/s) - FCU', 'GYRO Y (deg/s) - FCU', 'GYRO Z (deg/s) - FCU', 'ACC X (G) - FCR', 'ACC Y (G) - FCR', 'ACC Z (G) - FCR', 'GYRO X (deg/s) - FCR', 'GYRO Y (deg/s) - FCR', 'GYRO Z (deg/s) - FCR']\n",
      "[process_file] Format: COMPACT_FORMAT\n",
      "[process_file] DataFrame shape after reading: (662099, 27)\n",
      "[process_file] Descriptive Statistics:\n",
      "       EMG 1 (mV) - FCU  EMG 1 (mV) - FCR                      Timestamp  \\\n",
      "count     662099.000000     662099.000000                         662099   \n",
      "mean          -0.007815          0.012221  2025-02-27 14:38:58.109250048   \n",
      "min           -8.980942         -4.700450            2025-02-27 14:36:24   \n",
      "25%           -0.015106          0.003861  2025-02-27 14:37:41.054625024   \n",
      "50%           -0.008393          0.011917  2025-02-27 14:38:58.109250048   \n",
      "75%           -0.000336          0.019638  2025-02-27 14:40:15.163875072   \n",
      "max            7.808011          5.499916     2025-02-27 14:41:32.218500   \n",
      "std            0.117751          0.108818                            NaN   \n",
      "\n",
      "       EMG 1 (mV) - FDS  ACC X (G) - FDS  ACC Y (G) - FDS  ACC Z (G) - FDS  \\\n",
      "count               0.0              0.0              0.0              0.0   \n",
      "mean                NaN              NaN              NaN              NaN   \n",
      "min                 NaN              NaN              NaN              NaN   \n",
      "25%                 NaN              NaN              NaN              NaN   \n",
      "50%                 NaN              NaN              NaN              NaN   \n",
      "75%                 NaN              NaN              NaN              NaN   \n",
      "max                 NaN              NaN              NaN              NaN   \n",
      "std                 NaN              NaN              NaN              NaN   \n",
      "\n",
      "       GYRO X (deg/s) - FDS  GYRO Y (deg/s) - FDS  GYRO Z (deg/s) - FDS  ...  \\\n",
      "count                   0.0                   0.0                   0.0  ...   \n",
      "mean                    NaN                   NaN                   NaN  ...   \n",
      "min                     NaN                   NaN                   NaN  ...   \n",
      "25%                     NaN                   NaN                   NaN  ...   \n",
      "50%                     NaN                   NaN                   NaN  ...   \n",
      "75%                     NaN                   NaN                   NaN  ...   \n",
      "max                     NaN                   NaN                   NaN  ...   \n",
      "std                     NaN                   NaN                   NaN  ...   \n",
      "\n",
      "       ACC Z (G) - FCU  GYRO X (deg/s) - FCU  GYRO Y (deg/s) - FCU  \\\n",
      "count              0.0                   0.0                   0.0   \n",
      "mean               NaN                   NaN                   NaN   \n",
      "min                NaN                   NaN                   NaN   \n",
      "25%                NaN                   NaN                   NaN   \n",
      "50%                NaN                   NaN                   NaN   \n",
      "75%                NaN                   NaN                   NaN   \n",
      "max                NaN                   NaN                   NaN   \n",
      "std                NaN                   NaN                   NaN   \n",
      "\n",
      "       GYRO Z (deg/s) - FCU  ACC X (G) - FCR  ACC Y (G) - FCR  \\\n",
      "count                   0.0              0.0              0.0   \n",
      "mean                    NaN              NaN              NaN   \n",
      "min                     NaN              NaN              NaN   \n",
      "25%                     NaN              NaN              NaN   \n",
      "50%                     NaN              NaN              NaN   \n",
      "75%                     NaN              NaN              NaN   \n",
      "max                     NaN              NaN              NaN   \n",
      "std                     NaN              NaN              NaN   \n",
      "\n",
      "       ACC Z (G) - FCR  GYRO X (deg/s) - FCR  GYRO Y (deg/s) - FCR  \\\n",
      "count              0.0                   0.0                   0.0   \n",
      "mean               NaN                   NaN                   NaN   \n",
      "min                NaN                   NaN                   NaN   \n",
      "25%                NaN                   NaN                   NaN   \n",
      "50%                NaN                   NaN                   NaN   \n",
      "75%                NaN                   NaN                   NaN   \n",
      "max                NaN                   NaN                   NaN   \n",
      "std                NaN                   NaN                   NaN   \n",
      "\n",
      "       GYRO Z (deg/s) - FCR  \n",
      "count                   0.0  \n",
      "mean                    NaN  \n",
      "min                     NaN  \n",
      "25%                     NaN  \n",
      "50%                     NaN  \n",
      "75%                     NaN  \n",
      "max                     NaN  \n",
      "std                     NaN  \n",
      "\n",
      "[8 rows x 22 columns]\n",
      "[process_file] Data types:\n",
      "EMG 1 (mV) - FCU                      float64\n",
      "EMG 1 (mV) - FCR                      float64\n",
      "Timestamp                      datetime64[ns]\n",
      "Application                            object\n",
      "Date/Time                              object\n",
      "Collection Length (seconds)            object\n",
      "HasTimeSeries                            bool\n",
      "FileFormat                             object\n",
      "EMG 1 (mV) - FDS                      float64\n",
      "ACC X (G) - FDS                       float64\n",
      "ACC Y (G) - FDS                       float64\n",
      "ACC Z (G) - FDS                       float64\n",
      "GYRO X (deg/s) - FDS                  float64\n",
      "GYRO Y (deg/s) - FDS                  float64\n",
      "GYRO Z (deg/s) - FDS                  float64\n",
      "ACC X (G) - FCU                       float64\n",
      "ACC Y (G) - FCU                       float64\n",
      "ACC Z (G) - FCU                       float64\n",
      "GYRO X (deg/s) - FCU                  float64\n",
      "GYRO Y (deg/s) - FCU                  float64\n",
      "GYRO Z (deg/s) - FCU                  float64\n",
      "ACC X (G) - FCR                       float64\n",
      "ACC Y (G) - FCR                       float64\n",
      "ACC Z (G) - FCR                       float64\n",
      "GYRO X (deg/s) - FCR                  float64\n",
      "GYRO Y (deg/s) - FCR                  float64\n",
      "GYRO Z (deg/s) - FCR                  float64\n",
      "dtype: object\n",
      "[process_file] Identified numeric sensor columns: ['ACC X (G) - FDS', 'ACC X (G) - FCU', 'ACC X (G) - FCR', 'ACC Y (G) - FDS', 'ACC Y (G) - FCU', 'ACC Y (G) - FCR', 'ACC Z (G) - FDS', 'ACC Z (G) - FCU', 'ACC Z (G) - FCR', 'GYRO X (deg/s) - FDS', 'GYRO X (deg/s) - FCU', 'GYRO X (deg/s) - FCR', 'GYRO Y (deg/s) - FDS', 'GYRO Y (deg/s) - FCU', 'GYRO Y (deg/s) - FCR', 'GYRO Z (deg/s) - FDS', 'GYRO Z (deg/s) - FCU', 'GYRO Z (deg/s) - FCR', 'EMG 1 (mV) - FCU', 'EMG 1 (mV) - FCR', 'EMG 1 (mV) - FDS']\n",
      "[process_file] Rows with blank numeric values: 0\n",
      "[process_file] Data shape after cleaning: (662099, 27)\n",
      "File processing completed.\n",
      "\n",
      "\n",
      "[process_file] Processing file: ../../data/raw/emg_data\\2-27-25_mocap_1.csv\n",
      "[read_sensor_data_with_metadata] Format detected: COMPACT_WITH_TIMESERIES\n",
      "[read_sensor_data_with_metadata] SensorGroups: ['FCU (81770)', 'FCR (81745)']\n",
      "[read_sensor_data_with_metadata] SensorModes: ['sensor mode: 40', 'sensor mode: 40', 'sensor mode: 40']\n",
      "[read_sensor_data_with_metadata] Time series format detected: 2 sensors, 4 columns\n",
      "[read_sensor_data_with_metadata] Created unique column names for time series format: ['EMG 1 Time Series (s) - FCU', 'EMG 1 (mV) - FCU', 'EMG 1 Time Series (s) - FCR', 'EMG 1 (mV) - FCR']\n",
      "[read_sensor_data_with_metadata] Using column names: ['EMG 1 Time Series (s) - FCU', 'EMG 1 (mV) - FCU', 'EMG 1 Time Series (s) - FCR', 'EMG 1 (mV) - FCR']\n",
      "[read_sensor_data_with_metadata] Created timestamps from EMG 1 Time Series (s) - FCU\n",
      "[read_sensor_data_with_metadata] Missing sensors: ['FDS']\n",
      "[read_sensor_data_with_metadata] Missing ACC columns for FCU\n",
      "[read_sensor_data_with_metadata] Missing GYRO columns for FCU\n",
      "[read_sensor_data_with_metadata] Missing ACC columns for FCR\n",
      "[read_sensor_data_with_metadata] Missing GYRO columns for FCR\n",
      "[read_sensor_data_with_metadata] Final DataFrame shape: (459969, 29)\n",
      "[read_sensor_data_with_metadata] Final column names: ['EMG 1 Time Series (s) - FCU', 'EMG 1 (mV) - FCU', 'EMG 1 Time Series (s) - FCR', 'EMG 1 (mV) - FCR', 'Timestamp', 'Application', 'Date/Time', 'Collection Length (seconds)', 'HasTimeSeries', 'FileFormat', 'EMG 1 (mV) - FDS', 'ACC X (G) - FDS', 'ACC Y (G) - FDS', 'ACC Z (G) - FDS', 'GYRO X (deg/s) - FDS', 'GYRO Y (deg/s) - FDS', 'GYRO Z (deg/s) - FDS', 'ACC X (G) - FCU', 'ACC Y (G) - FCU', 'ACC Z (G) - FCU', 'GYRO X (deg/s) - FCU', 'GYRO Y (deg/s) - FCU', 'GYRO Z (deg/s) - FCU', 'ACC X (G) - FCR', 'ACC Y (G) - FCR', 'ACC Z (G) - FCR', 'GYRO X (deg/s) - FCR', 'GYRO Y (deg/s) - FCR', 'GYRO Z (deg/s) - FCR']\n",
      "[process_file] Format: COMPACT_WITH_TIMESERIES\n",
      "[process_file] DataFrame shape after reading: (459969, 29)\n",
      "[process_file] Descriptive Statistics:\n",
      "       EMG 1 Time Series (s) - FCU  EMG 1 (mV) - FCU  \\\n",
      "count                459969.000000     459969.000000   \n",
      "mean                    107.061517         -0.007944   \n",
      "min                       0.000000         -2.986709   \n",
      "25%                      53.530759         -0.010071   \n",
      "50%                     107.061517         -0.008393   \n",
      "75%                     160.592276         -0.005707   \n",
      "max                     214.123034          1.666072   \n",
      "std                      61.812197          0.037662   \n",
      "\n",
      "       EMG 1 Time Series (s) - FCR  EMG 1 (mV) - FCR  \\\n",
      "count                459969.000000     459969.000000   \n",
      "mean                    107.061517          0.012219   \n",
      "min                       0.000000         -1.537835   \n",
      "25%                      53.530759          0.010407   \n",
      "50%                     107.061517          0.012253   \n",
      "75%                     160.592276          0.014267   \n",
      "max                     214.123034          2.169451   \n",
      "std                      61.812197          0.036744   \n",
      "\n",
      "                           Timestamp  EMG 1 (mV) - FDS  ACC X (G) - FDS  \\\n",
      "count                         459969               0.0              0.0   \n",
      "mean   2025-02-27 14:50:19.061517568               NaN              NaN   \n",
      "min              2025-02-27 14:48:32               NaN              NaN   \n",
      "25%    2025-02-27 14:49:25.530758656               NaN              NaN   \n",
      "50%    2025-02-27 14:50:19.061517312               NaN              NaN   \n",
      "75%    2025-02-27 14:51:12.592275968               NaN              NaN   \n",
      "max    2025-02-27 14:52:06.123034500               NaN              NaN   \n",
      "std                              NaN               NaN              NaN   \n",
      "\n",
      "       ACC Y (G) - FDS  ACC Z (G) - FDS  GYRO X (deg/s) - FDS  ...  \\\n",
      "count              0.0              0.0                   0.0  ...   \n",
      "mean               NaN              NaN                   NaN  ...   \n",
      "min                NaN              NaN                   NaN  ...   \n",
      "25%                NaN              NaN                   NaN  ...   \n",
      "50%                NaN              NaN                   NaN  ...   \n",
      "75%                NaN              NaN                   NaN  ...   \n",
      "max                NaN              NaN                   NaN  ...   \n",
      "std                NaN              NaN                   NaN  ...   \n",
      "\n",
      "       ACC Z (G) - FCU  GYRO X (deg/s) - FCU  GYRO Y (deg/s) - FCU  \\\n",
      "count              0.0                   0.0                   0.0   \n",
      "mean               NaN                   NaN                   NaN   \n",
      "min                NaN                   NaN                   NaN   \n",
      "25%                NaN                   NaN                   NaN   \n",
      "50%                NaN                   NaN                   NaN   \n",
      "75%                NaN                   NaN                   NaN   \n",
      "max                NaN                   NaN                   NaN   \n",
      "std                NaN                   NaN                   NaN   \n",
      "\n",
      "       GYRO Z (deg/s) - FCU  ACC X (G) - FCR  ACC Y (G) - FCR  \\\n",
      "count                   0.0              0.0              0.0   \n",
      "mean                    NaN              NaN              NaN   \n",
      "min                     NaN              NaN              NaN   \n",
      "25%                     NaN              NaN              NaN   \n",
      "50%                     NaN              NaN              NaN   \n",
      "75%                     NaN              NaN              NaN   \n",
      "max                     NaN              NaN              NaN   \n",
      "std                     NaN              NaN              NaN   \n",
      "\n",
      "       ACC Z (G) - FCR  GYRO X (deg/s) - FCR  GYRO Y (deg/s) - FCR  \\\n",
      "count              0.0                   0.0                   0.0   \n",
      "mean               NaN                   NaN                   NaN   \n",
      "min                NaN                   NaN                   NaN   \n",
      "25%                NaN                   NaN                   NaN   \n",
      "50%                NaN                   NaN                   NaN   \n",
      "75%                NaN                   NaN                   NaN   \n",
      "max                NaN                   NaN                   NaN   \n",
      "std                NaN                   NaN                   NaN   \n",
      "\n",
      "       GYRO Z (deg/s) - FCR  \n",
      "count                   0.0  \n",
      "mean                    NaN  \n",
      "min                     NaN  \n",
      "25%                     NaN  \n",
      "50%                     NaN  \n",
      "75%                     NaN  \n",
      "max                     NaN  \n",
      "std                     NaN  \n",
      "\n",
      "[8 rows x 24 columns]\n",
      "[process_file] Data types:\n",
      "EMG 1 Time Series (s) - FCU           float64\n",
      "EMG 1 (mV) - FCU                      float64\n",
      "EMG 1 Time Series (s) - FCR           float64\n",
      "EMG 1 (mV) - FCR                      float64\n",
      "Timestamp                      datetime64[ns]\n",
      "Application                            object\n",
      "Date/Time                              object\n",
      "Collection Length (seconds)            object\n",
      "HasTimeSeries                            bool\n",
      "FileFormat                             object\n",
      "EMG 1 (mV) - FDS                      float64\n",
      "ACC X (G) - FDS                       float64\n",
      "ACC Y (G) - FDS                       float64\n",
      "ACC Z (G) - FDS                       float64\n",
      "GYRO X (deg/s) - FDS                  float64\n",
      "GYRO Y (deg/s) - FDS                  float64\n",
      "GYRO Z (deg/s) - FDS                  float64\n",
      "ACC X (G) - FCU                       float64\n",
      "ACC Y (G) - FCU                       float64\n",
      "ACC Z (G) - FCU                       float64\n",
      "GYRO X (deg/s) - FCU                  float64\n",
      "GYRO Y (deg/s) - FCU                  float64\n",
      "GYRO Z (deg/s) - FCU                  float64\n",
      "ACC X (G) - FCR                       float64\n",
      "ACC Y (G) - FCR                       float64\n",
      "ACC Z (G) - FCR                       float64\n",
      "GYRO X (deg/s) - FCR                  float64\n",
      "GYRO Y (deg/s) - FCR                  float64\n",
      "GYRO Z (deg/s) - FCR                  float64\n",
      "dtype: object\n",
      "[process_file] Identified numeric sensor columns: ['ACC X (G) - FDS', 'ACC X (G) - FCU', 'ACC X (G) - FCR', 'ACC Y (G) - FDS', 'ACC Y (G) - FCU', 'ACC Y (G) - FCR', 'ACC Z (G) - FDS', 'ACC Z (G) - FCU', 'ACC Z (G) - FCR', 'GYRO X (deg/s) - FDS', 'GYRO X (deg/s) - FCU', 'GYRO X (deg/s) - FCR', 'GYRO Y (deg/s) - FDS', 'GYRO Y (deg/s) - FCU', 'GYRO Y (deg/s) - FCR', 'GYRO Z (deg/s) - FDS', 'GYRO Z (deg/s) - FCU', 'GYRO Z (deg/s) - FCR', 'EMG 1 (mV) - FCU', 'EMG 1 (mV) - FCR', 'EMG 1 (mV) - FDS']\n",
      "[process_file] Rows with blank numeric values: 0\n",
      "[process_file] Data shape after cleaning: (459969, 29)\n",
      "[process_file] Removed 2 time series columns\n",
      "File processing completed.\n",
      "\n",
      "[main] File formats detected: {'FULL_FORMAT': 2, 'COMPACT_FORMAT': 1, 'COMPACT_WITH_TIMESERIES': 1}\n",
      "[main] Final stacked DataFrame shape: (1431654, 28)\n",
      "[main] Final columns: ['EMG 1 (mV) - FDS', 'ACC X (G) - FDS', 'ACC Y (G) - FDS', 'ACC Z (G) - FDS', 'GYRO X (deg/s) - FDS', 'GYRO Y (deg/s) - FDS', 'GYRO Z (deg/s) - FDS', 'EMG 1 (mV) - FCU', 'ACC X (G) - FCU', 'ACC Y (G) - FCU', 'ACC Z (G) - FCU', 'GYRO X (deg/s) - FCU', 'GYRO Y (deg/s) - FCU', 'GYRO Z (deg/s) - FCU', 'EMG 1 (mV) - FCR', 'Timestamp', 'Application', 'Date/Time', 'Collection Length (seconds)', 'HasTimeSeries', 'FileFormat', 'ACC X (G) - FCR', 'ACC Y (G) - FCR', 'ACC Z (G) - FCR', 'GYRO X (deg/s) - FCR', 'GYRO Y (deg/s) - FCR', 'GYRO Z (deg/s) - FCR', 'SourceFile']\n",
      "Final processed data saved to: ../../data/processed/combined_emg_data.parquet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "def detect_file_format(lines, debug=False):\n",
    "    \"\"\"\n",
    "    Detects the file format from the header lines.\n",
    "    \n",
    "    Parameters:\n",
    "      lines (list): List of header lines from the file.\n",
    "      debug (bool): If True, prints debug info.\n",
    "      \n",
    "    Returns:\n",
    "      str: Format descriptor string.\n",
    "    \"\"\"\n",
    "    has_time_series = any(\"Time Series\" in line for line in lines[:10])\n",
    "    \n",
    "    # Check sensor group line\n",
    "    sensor_group_line = lines[3].strip()\n",
    "    sensor_tokens = [token.strip() for token in sensor_group_line.split(',')]\n",
    "    non_empty_tokens = [token for token in sensor_tokens if token]\n",
    "    \n",
    "    if len(non_empty_tokens) == 3 and \"FDS\" in sensor_group_line and \"FCU\" in sensor_group_line and \"FCR\" in sensor_group_line:\n",
    "        return \"FULL_FORMAT\"\n",
    "    elif len(non_empty_tokens) == 2 and \"FCU\" in sensor_group_line and \"FCR\" in sensor_group_line:\n",
    "        if has_time_series:\n",
    "            return \"COMPACT_WITH_TIMESERIES\"\n",
    "        else:\n",
    "            return \"COMPACT_FORMAT\"\n",
    "    else:\n",
    "        return \"UNKNOWN_FORMAT\"\n",
    "\n",
    "\n",
    "def read_sensor_data_with_metadata(file_path, debug=False):\n",
    "    \"\"\"\n",
    "    Enhanced reader that handles various EMG data formats:\n",
    "    \n",
    "    Format 1: 3 sensors (FDS, FCU, FCR) with ACC and GYRO data\n",
    "    Example: \n",
    "        FDS (81770), , , , , , , FCU (81728), , , , , , , FCR (81745)\n",
    "        sensor mode: 50, , , , , , , sensor mode: 50, , , , , , , sensor mode: 40\n",
    "    \n",
    "    Format 2: 2 sensors (FCU, FCR) with only EMG data, no time series\n",
    "    Example:\n",
    "        FCU (81770), FCR (81745)\n",
    "        sensor mode: 40, sensor mode: 40\n",
    "    \n",
    "    Format 3: 2 sensors with time series columns\n",
    "    Example:\n",
    "        FCU (81770), , FCR (81745)\n",
    "        sensor mode: 40, , sensor mode: 40\n",
    "        EMG 1 Time Series (s), EMG 1 (mV), EMG 1 Time Series (s), EMG 1 (mV)\n",
    "    \n",
    "    It standardizes column names and fills in nulls for missing sensors/channels.\n",
    "    \n",
    "    Parameters:\n",
    "      file_path (str): Path to the CSV file.\n",
    "      debug (bool): If True, prints detailed debug output.\n",
    "    \n",
    "    Returns:\n",
    "      df (pd.DataFrame): DataFrame with standardized columns.\n",
    "      metadata (dict): Dictionary of parsed metadata.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        all_lines = f.readlines()\n",
    "    \n",
    "    # Detect file format by scanning header\n",
    "    file_format = detect_file_format(all_lines, debug=debug)\n",
    "    \n",
    "    metadata = {}\n",
    "    # --- Parse first 3 lines (common for all formats) ---\n",
    "    # Line 0: Application\n",
    "    line = all_lines[0].strip()\n",
    "    if ',' in line:\n",
    "        key, value = line.split(',', 1)\n",
    "        metadata[key.strip().rstrip(':')] = value.strip()\n",
    "    else:\n",
    "        metadata['Application'] = line\n",
    "\n",
    "    # Line 1: Date/Time\n",
    "    line = all_lines[1].strip()\n",
    "    if ',' in line:\n",
    "        key, value = line.split(',', 1)\n",
    "        metadata[key.strip().rstrip(':')] = value.strip()\n",
    "    else:\n",
    "        metadata['Date/Time'] = line\n",
    "\n",
    "    # Line 2: Collection Length (seconds)\n",
    "    line = all_lines[2].strip()\n",
    "    if ',' in line:\n",
    "        key, value = line.split(',', 1)\n",
    "        metadata[key.strip().rstrip(':')] = value.strip()\n",
    "    else:\n",
    "        metadata['Collection Length (seconds)'] = line\n",
    "\n",
    "    # --- Determine if we have time series columns ---\n",
    "    has_time_series = any(\"Time Series\" in line for line in all_lines[:10])\n",
    "    metadata['HasTimeSeries'] = has_time_series\n",
    "    metadata['FileFormat'] = file_format\n",
    "    \n",
    "    # --- Parse sensor groups ---\n",
    "    sensor_group_line = all_lines[3].strip()\n",
    "    sensor_mode_line = all_lines[4].strip()\n",
    "    \n",
    "    if ',' in sensor_group_line and len(sensor_group_line.split(',')) > 1:\n",
    "        # Multiple sensors format\n",
    "        sensor_group_tokens = [token.strip() for token in sensor_group_line.split(',')]\n",
    "        \n",
    "        # For Format 3, filter out empty tokens\n",
    "        if file_format == \"COMPACT_WITH_TIMESERIES\":\n",
    "            non_empty_tokens = [token for token in sensor_group_tokens if token]\n",
    "            sensor_group_tokens = non_empty_tokens\n",
    "            \n",
    "        # Propagate non-empty values forward\n",
    "        sensor_groups = []\n",
    "        last = None\n",
    "        for token in sensor_group_tokens:\n",
    "            if token:\n",
    "                last = token\n",
    "            sensor_groups.append(last if last is not None else \"\")\n",
    "        \n",
    "        # Similarly for sensor modes\n",
    "        sensor_mode_tokens = [token.strip() for token in sensor_mode_line.split(',')]\n",
    "        sensor_modes = []\n",
    "        last_mode = None\n",
    "        for token in sensor_mode_tokens:\n",
    "            if token:\n",
    "                last_mode = token\n",
    "            sensor_modes.append(last_mode if last_mode is not None else \"\")\n",
    "        \n",
    "        # Store these in metadata\n",
    "        metadata['SensorGroups'] = sensor_groups\n",
    "        metadata['SensorModes'] = sensor_modes\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"[read_sensor_data_with_metadata] Format detected: {file_format}\")\n",
    "            print(f\"[read_sensor_data_with_metadata] SensorGroups: {sensor_groups}\")\n",
    "            print(f\"[read_sensor_data_with_metadata] SensorModes: {sensor_modes}\")\n",
    "    else:\n",
    "        # Legacy dataset: use line 3 and 4 as single values.\n",
    "        metadata['Sensor'] = sensor_group_line\n",
    "        metadata['Sensor Mode'] = sensor_mode_line\n",
    "\n",
    "    # --- Header row for sensor data ---\n",
    "    header_line = all_lines[5].strip()\n",
    "    original_col_names = [col.strip() for col in header_line.split(',')]\n",
    "    \n",
    "    # Special handling for COMPACT_WITH_TIMESERIES format to avoid duplicate column names\n",
    "    if file_format == \"COMPACT_WITH_TIMESERIES\" and len(sensor_groups) < len(original_col_names):\n",
    "        if debug:\n",
    "            print(f\"[read_sensor_data_with_metadata] Time series format detected: {len(sensor_groups)} sensors, {len(original_col_names)} columns\")\n",
    "        \n",
    "        # Get unique sensor names\n",
    "        sensor_names = []\n",
    "        for group in sensor_groups:\n",
    "            sensor_name = group.split('(')[0].strip()\n",
    "            sensor_names.append(sensor_name)\n",
    "        \n",
    "        # Create unique column names by alternating between sensors\n",
    "        new_col_names = []\n",
    "        for i, col in enumerate(original_col_names):\n",
    "            # Calculate which sensor this column belongs to\n",
    "            sensor_idx = i // (len(original_col_names) // len(sensor_names))\n",
    "            if sensor_idx >= len(sensor_names):\n",
    "                sensor_idx = len(sensor_names) - 1\n",
    "            \n",
    "            # Append sensor name to column for uniqueness\n",
    "            sensor_name = sensor_names[sensor_idx]\n",
    "            new_col_names.append(f\"{col} - {sensor_name}\")\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"[read_sensor_data_with_metadata] Created unique column names for time series format: {new_col_names}\")\n",
    "    \n",
    "    # Update column names by appending sensor group for other formats\n",
    "    elif 'SensorGroups' in metadata:\n",
    "        if len(metadata['SensorGroups']) >= len(original_col_names):\n",
    "            new_col_names = []\n",
    "            for i, col in enumerate(original_col_names):\n",
    "                group = metadata['SensorGroups'][i]\n",
    "                if group:\n",
    "                    # Extract sensor name (e.g., \"FCU\" from \"FCU (81770)\")\n",
    "                    sensor_name = group.split('(')[0].strip()\n",
    "                    new_col_names.append(f\"{col} - {sensor_name}\")\n",
    "                else:\n",
    "                    new_col_names.append(col)\n",
    "            if debug:\n",
    "                print(\"[read_sensor_data_with_metadata] New column names set with sensor names.\")\n",
    "        else:\n",
    "            # For other formats with insufficient sensor groups, make column names unique with index\n",
    "            if debug:\n",
    "                print(f\"[read_sensor_data_with_metadata] Warning: Not enough sensor group entries ({len(metadata['SensorGroups'])}) for columns ({len(original_col_names)})\")\n",
    "            \n",
    "            # Check for potential duplicates in original column names\n",
    "            if len(set(original_col_names)) < len(original_col_names):\n",
    "                if debug:\n",
    "                    print(\"[read_sensor_data_with_metadata] Duplicate column names detected, making them unique\")\n",
    "                new_col_names = []\n",
    "                for i, col in enumerate(original_col_names):\n",
    "                    new_col_names.append(f\"{col}_col{i}\")\n",
    "            else:\n",
    "                new_col_names = original_col_names\n",
    "    else:\n",
    "        # For all other formats, ensure column names are unique\n",
    "        if len(set(original_col_names)) < len(original_col_names):\n",
    "            if debug:\n",
    "                print(\"[read_sensor_data_with_metadata] Duplicate column names detected, making them unique\")\n",
    "            new_col_names = []\n",
    "            for i, col in enumerate(original_col_names):\n",
    "                new_col_names.append(f\"{col}_col{i}\")\n",
    "        else:\n",
    "            new_col_names = original_col_names\n",
    "\n",
    "    if debug:\n",
    "        print(f\"[read_sensor_data_with_metadata] Using column names: {new_col_names}\")\n",
    "\n",
    "    # Determine sample rate line index (typically line 6)\n",
    "    sample_rate_line_idx = 6\n",
    "    \n",
    "    # Read the sensor data (starting after sample rate line)\n",
    "    data_str = ''.join(all_lines[sample_rate_line_idx + 1:])\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(StringIO(data_str), header=None, names=new_col_names)\n",
    "    except ValueError as e:\n",
    "        if \"Duplicate names\" in str(e):\n",
    "            if debug:\n",
    "                print(f\"[read_sensor_data_with_metadata] Error: {e}. Adding unique suffixes to column names.\")\n",
    "            \n",
    "            # Add unique suffixes to ensure no duplicates\n",
    "            unique_col_names = []\n",
    "            for i, name in enumerate(new_col_names):\n",
    "                unique_col_names.append(f\"{name}_{i}\")\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"[read_sensor_data_with_metadata] Using modified column names: {unique_col_names}\")\n",
    "            \n",
    "            df = pd.read_csv(StringIO(data_str), header=None, names=unique_col_names)\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # Handle timestamp creation based on format\n",
    "    if has_time_series:\n",
    "        # Find time series columns\n",
    "        ts_cols = [col for col in df.columns if \"Time Series\" in col]\n",
    "        if ts_cols:\n",
    "            # Use the first time series column for timestamps\n",
    "            ts_col = ts_cols[0]\n",
    "            start_time = pd.to_datetime(metadata.get('Date/Time', None))\n",
    "            df['Timestamp'] = start_time + pd.to_timedelta(df[ts_col], unit='s')\n",
    "            if debug:\n",
    "                print(f\"[read_sensor_data_with_metadata] Created timestamps from {ts_col}\")\n",
    "        else:\n",
    "            # Fall back to generated timestamps\n",
    "            if debug:\n",
    "                print(\"[read_sensor_data_with_metadata] No time series columns found despite HasTimeSeries=True\")\n",
    "            collection_length = float(metadata.get('Collection Length (seconds)', 0))\n",
    "            start_time = pd.to_datetime(metadata.get('Date/Time', None))\n",
    "            num_samples = len(df)\n",
    "            time_offsets = np.linspace(0, collection_length, num_samples)\n",
    "            df['Timestamp'] = start_time + pd.to_timedelta(time_offsets, unit='s')\n",
    "    else:\n",
    "        # Create a running Timestamp column from metadata\n",
    "        collection_length = float(metadata.get('Collection Length (seconds)', 0))\n",
    "        start_time = pd.to_datetime(metadata.get('Date/Time', None))\n",
    "        num_samples = len(df)\n",
    "        time_offsets = np.linspace(0, collection_length, num_samples)\n",
    "        df['Timestamp'] = start_time + pd.to_timedelta(time_offsets, unit='s')\n",
    "\n",
    "    # Add metadata columns to the DataFrame (except sensor group and mode lists)\n",
    "    for key, value in metadata.items():\n",
    "        if key not in ['SensorGroups', 'SensorModes']:\n",
    "            df[key] = value\n",
    "    \n",
    "    # Check for required sensors and create placeholder columns if missing\n",
    "    all_sensors = ['FDS', 'FCU', 'FCR']\n",
    "    available_sensors = []\n",
    "    \n",
    "    # Identify which sensors are present\n",
    "    for col in df.columns:\n",
    "        for sensor in all_sensors:\n",
    "            if f\" - {sensor}\" in col and sensor not in available_sensors:\n",
    "                available_sensors.append(sensor)\n",
    "    \n",
    "    missing_sensors = [s for s in all_sensors if s not in available_sensors]\n",
    "    \n",
    "    # Add placeholders for missing sensors\n",
    "    if missing_sensors:\n",
    "        if debug:\n",
    "            print(f\"[read_sensor_data_with_metadata] Missing sensors: {missing_sensors}\")\n",
    "        \n",
    "        for sensor in missing_sensors:\n",
    "            # Add placeholder EMG column\n",
    "            df[f'EMG 1 (mV) - {sensor}'] = np.nan\n",
    "            \n",
    "            # Add placeholder accelerometer and gyroscope columns\n",
    "            df[f'ACC X (G) - {sensor}'] = np.nan\n",
    "            df[f'ACC Y (G) - {sensor}'] = np.nan\n",
    "            df[f'ACC Z (G) - {sensor}'] = np.nan\n",
    "            df[f'GYRO X (deg/s) - {sensor}'] = np.nan\n",
    "            df[f'GYRO Y (deg/s) - {sensor}'] = np.nan\n",
    "            df[f'GYRO Z (deg/s) - {sensor}'] = np.nan\n",
    "    \n",
    "    # Check for missing ACC and GYRO columns for available sensors\n",
    "    for sensor in available_sensors:\n",
    "        # Check if ACC columns exist for this sensor\n",
    "        if not any(col.startswith('ACC X') and f' - {sensor}' in col for col in df.columns):\n",
    "            if debug:\n",
    "                print(f\"[read_sensor_data_with_metadata] Missing ACC columns for {sensor}\")\n",
    "            df[f'ACC X (G) - {sensor}'] = np.nan\n",
    "            df[f'ACC Y (G) - {sensor}'] = np.nan\n",
    "            df[f'ACC Z (G) - {sensor}'] = np.nan\n",
    "        \n",
    "        # Check if GYRO columns exist for this sensor\n",
    "        if not any(col.startswith('GYRO X') and f' - {sensor}' in col for col in df.columns):\n",
    "            if debug:\n",
    "                print(f\"[read_sensor_data_with_metadata] Missing GYRO columns for {sensor}\")\n",
    "            df[f'GYRO X (deg/s) - {sensor}'] = np.nan\n",
    "            df[f'GYRO Y (deg/s) - {sensor}'] = np.nan\n",
    "            df[f'GYRO Z (deg/s) - {sensor}'] = np.nan\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"[read_sensor_data_with_metadata] Final DataFrame shape: {df.shape}\")\n",
    "        print(f\"[read_sensor_data_with_metadata] Final column names: {df.columns.tolist()}\")\n",
    "    else:\n",
    "        print(\"read_sensor_data_with_metadata completed.\")\n",
    "    \n",
    "    return df, metadata\n",
    "\n",
    "\n",
    "def process_file(file_path, debug=False):\n",
    "    \"\"\"\n",
    "    Processes a single sensor CSV file:\n",
    "      - Reads the file and its metadata.\n",
    "      - Performs cleaning and type conversion.\n",
    "    \n",
    "    Parameters:\n",
    "      file_path (str): Path to the CSV file.\n",
    "      debug (bool): If True, prints detailed debug output.\n",
    "    \n",
    "    Returns:\n",
    "      pd.DataFrame: Processed DataFrame.\n",
    "    \"\"\"\n",
    "    if debug:\n",
    "        print(f\"\\n[process_file] Processing file: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Processing file: {os.path.basename(file_path)}\")\n",
    "\n",
    "    # Step 1: Read data and metadata.\n",
    "    df, metadata = read_sensor_data_with_metadata(file_path, debug=debug)\n",
    "    if debug:\n",
    "        print(f\"[process_file] Format: {metadata.get('FileFormat', 'Unknown')}\")\n",
    "        print(f\"[process_file] DataFrame shape after reading: {df.shape}\")\n",
    "    else:\n",
    "        print(\"Data read completed.\")\n",
    "\n",
    "    # Step 2: Display minimal summary if in debug mode.\n",
    "    if debug:\n",
    "        print(f\"[process_file] Descriptive Statistics:\\n{df.describe()}\")\n",
    "        print(f\"[process_file] Data types:\\n{df.dtypes}\")\n",
    "    else:\n",
    "        print(\"Basic summary displayed.\")\n",
    "\n",
    "    # Step 3: Dynamically identify numeric sensor columns.\n",
    "    base_names = ['ACC X (G)', 'ACC Y (G)', 'ACC Z (G)', \n",
    "                  'GYRO X (deg/s)', 'GYRO Y (deg/s)', 'GYRO Z (deg/s)',\n",
    "                  'EMG 1 (mV)']\n",
    "    numeric_cols = []\n",
    "    for base in base_names:\n",
    "        matches = [col for col in df.columns if col.startswith(base)]\n",
    "        numeric_cols.extend(matches)\n",
    "    if debug:\n",
    "        print(f\"[process_file] Identified numeric sensor columns: {numeric_cols}\")\n",
    "\n",
    "    # Clean data: Remove rows with blank numeric values (but keep rows with NaN).\n",
    "    # Only check non-NaN columns to avoid removing all rows when a whole column is NaN\n",
    "    non_nan_cols = [col for col in numeric_cols if not df[col].isna().all()]\n",
    "    if non_nan_cols:\n",
    "        mask = df[non_nan_cols].apply(lambda col: col.astype(str).str.strip() == '').any(axis=1)\n",
    "        if debug:\n",
    "            print(f\"[process_file] Rows with blank numeric values: {mask.sum()}\")\n",
    "        df = df[~mask]\n",
    "    else:\n",
    "        if debug:\n",
    "            print(\"[process_file] All numeric columns are NaN. Skipping blank value check.\")\n",
    "\n",
    "    # Convert identified numeric columns to numeric type.\n",
    "    for col in numeric_cols:\n",
    "        try:\n",
    "            if not df[col].isna().all():  # Skip conversion if column is all NaN\n",
    "                df[col] = pd.to_numeric(df[col], errors='raise')\n",
    "        except Exception as e:\n",
    "            print(f\"[process_file] Error converting column {col}: {e}\")\n",
    "            if debug:\n",
    "                raise\n",
    "    if debug:\n",
    "        print(f\"[process_file] Data shape after cleaning: {df.shape}\")\n",
    "\n",
    "    # Remove the Time Series columns as they're redundant after timestamp creation\n",
    "    ts_cols = [col for col in df.columns if \"Time Series\" in col]\n",
    "    if ts_cols:\n",
    "        df = df.drop(columns=ts_cols)\n",
    "        if debug:\n",
    "            print(f\"[process_file] Removed {len(ts_cols)} time series columns\")\n",
    "\n",
    "    print(\"File processing completed.\\n\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def main(debug=False, input_folder='./data/raw/', output_file='./data/processed/processed_emg_data.parquet'):\n",
    "    \"\"\"\n",
    "    Processes all CSV files in the specified folder, stacks them into one DataFrame,\n",
    "    and writes the output to a Parquet file.\n",
    "    \n",
    "    Parameters:\n",
    "      debug (bool): If True, prints detailed debug information.\n",
    "      input_folder (str): Folder containing the CSV files.\n",
    "      output_file (str): Path for the output Parquet file.\n",
    "    \n",
    "    Returns:\n",
    "      pd.DataFrame: Final processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Ensure input folder exists.\n",
    "    if not os.path.isdir(input_folder):\n",
    "        raise FileNotFoundError(f\"Input folder '{input_folder}' does not exist.\")\n",
    "    \n",
    "    # Find all CSV files in the folder.\n",
    "    csv_files = glob.glob(os.path.join(input_folder, '*.csv'))\n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(\"No CSV files found in the input folder.\")\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"[main] Found {len(csv_files)} CSV files in '{input_folder}'.\")\n",
    "    else:\n",
    "        print(f\"Found {len(csv_files)} CSV file(s).\")\n",
    "\n",
    "    processed_dfs = []\n",
    "    formats_found = {}\n",
    "    \n",
    "    for file in csv_files:\n",
    "        df = process_file(file, debug=debug)\n",
    "        \n",
    "        # Keep track of which formats were found\n",
    "        format_type = df['FileFormat'].iloc[0] if 'FileFormat' in df.columns else 'Unknown'\n",
    "        formats_found[format_type] = formats_found.get(format_type, 0) + 1\n",
    "        \n",
    "        # Add a column to indicate source file.\n",
    "        df['SourceFile'] = os.path.basename(file)\n",
    "        processed_dfs.append(df)\n",
    "    \n",
    "    # Stack all DataFrames (row-wise).\n",
    "    final_df = pd.concat(processed_dfs, ignore_index=True)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"[main] File formats detected: {formats_found}\")\n",
    "        print(f\"[main] Final stacked DataFrame shape: {final_df.shape}\")\n",
    "        print(f\"[main] Final columns: {final_df.columns.tolist()}\")\n",
    "    else:\n",
    "        print(f\"File formats detected: {formats_found}\")\n",
    "        print(\"All files processed and stacked.\")\n",
    "\n",
    "    # Save final DataFrame to Parquet.\n",
    "    output_dir = os.path.dirname(output_file)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    final_df.to_parquet(output_file, index=False)\n",
    "    print(f\"Final processed data saved to: {output_file}\")\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "# Run the module when executed as a script.\n",
    "if __name__ == \"__main__\":\n",
    "    # Set debug=True for detailed output, or False for minimal output.\n",
    "    processed_df = main(\n",
    "        debug=True,\n",
    "        input_folder='../../data/raw/emg_data/',  # Specify your input folder path here.\n",
    "        output_file='../../data/processed/combined_emg_data.parquet'  # Specify your output file path here.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science_fatigue_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
